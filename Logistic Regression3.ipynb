{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "813b2d41",
   "metadata": {},
   "source": [
    "# Logistic Regression 3: Classification Metrics, Multiclass Problems, and Model Deployment\n",
    "This notebook covers precision, recall, F1 score, ROC/AUC, metric selection, multiclass classification, logistic regression for multiclass, end-to-end project steps, and model deployment (including multi-cloud)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432a6102",
   "metadata": {},
   "source": [
    "## Q1. Explain the concept of precision and recall in the context of classification models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1361b1",
   "metadata": {},
   "source": [
    "- **Precision:** The proportion of positive predictions that are actually correct. Precision = TP / (TP + FP)\n",
    "- **Recall:** The proportion of actual positives that are correctly identified. Recall = TP / (TP + FN)\n",
    "\n",
    "Precision focuses on prediction accuracy, while recall focuses on capturing all actual positives."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effdd6dd",
   "metadata": {},
   "source": [
    "## Q2. What is the F1 score and how is it calculated? How is it different from precision and recall?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee450332",
   "metadata": {},
   "source": [
    "The **F1 score** is the harmonic mean of precision and recall:\n",
    "\n",
    "F1 = 2 * (Precision * Recall) / (Precision + Recall)\n",
    "\n",
    "It balances the trade-off between precision and recall, especially useful when classes are imbalanced."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b69203f",
   "metadata": {},
   "source": [
    "## Q3. What is ROC and AUC, and how are they used to evaluate the performance of classification models?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab88212",
   "metadata": {},
   "source": [
    "- **ROC (Receiver Operating Characteristic) curve:** Plots true positive rate vs. false positive rate at various thresholds.\n",
    "- **AUC (Area Under the Curve):** Measures the overall ability of the model to distinguish between classes. Higher AUC indicates better performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6080c899",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: ROC and AUC\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "probs = [0.1, 0.4, 0.35, 0.8]\n",
    "y_true = [0, 0, 1, 1]\n",
    "fpr, tpr, _ = roc_curve(y_true, probs)\n",
    "auc = roc_auc_score(y_true, probs)\n",
    "plt.plot(fpr, tpr, label=f'AUC = {auc:.2f}')\n",
    "plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ac3161",
   "metadata": {},
   "source": [
    "## Q4. How do you choose the best metric to evaluate the performance of a classification model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8583e9de",
   "metadata": {},
   "source": [
    "Choose the metric based on the problem context:\n",
    "- Use **accuracy** for balanced classes.\n",
    "- Use **precision** when false positives are costly.\n",
    "- Use **recall** when false negatives are costly.\n",
    "- Use **F1 score** for imbalanced classes.\n",
    "- Use **AUC** for overall discrimination ability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00e453b",
   "metadata": {},
   "source": [
    "## What is multiclass classification and how is it different from binary classification?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d6c23a",
   "metadata": {},
   "source": [
    "- **Binary classification:** Predicts one of two possible classes (e.g., spam vs. not spam).\n",
    "- **Multiclass classification:** Predicts one of three or more classes (e.g., classifying types of flowers).\n",
    "\n",
    "Multiclass requires different algorithms or strategies (e.g., one-vs-rest, softmax) compared to binary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3810a46",
   "metadata": {},
   "source": [
    "## Q5. Explain how logistic regression can be used for multiclass classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a529c28c",
   "metadata": {},
   "source": [
    "Logistic regression can be extended to multiclass problems using strategies like **one-vs-rest (OvR)** or **multinomial (softmax)**. In scikit-learn, set `multi_class='ovr'` or `multi_class='multinomial'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ab6db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Multiclass logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "X, y = load_iris(return_X_y=True)\n",
    "logreg_multi = LogisticRegression(multi_class='multinomial', solver='lbfgs')\n",
    "logreg_multi.fit(X, y)\n",
    "print('Classes:', logreg_multi.classes_)\n",
    "print('Coefficients:', logreg_multi.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc8e29d",
   "metadata": {},
   "source": [
    "## Q6. Describe the steps involved in an end-to-end project for multiclass classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d7210f",
   "metadata": {},
   "source": [
    "1. Define the problem and collect data\n",
    "2. Data preprocessing (cleaning, encoding, scaling)\n",
    "3. Exploratory data analysis (EDA)\n",
    "4. Feature engineering/selection\n",
    "5. Model selection and training\n",
    "6. Model evaluation (using multiclass metrics)\n",
    "7. Hyperparameter tuning\n",
    "8. Model interpretation\n",
    "9. Deployment and monitoring"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28eac631",
   "metadata": {},
   "source": [
    "## Q7. What is model deployment and why is it important?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1799ef73",
   "metadata": {},
   "source": [
    "Model deployment is the process of making a trained model available for use in production (e.g., via an API or web app). It is important because it enables real-world predictions and business value from machine learning models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611e0632",
   "metadata": {},
   "source": [
    "## Q8. Explain how multi-cloud platforms are used for model deployment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e11e56",
   "metadata": {},
   "source": [
    "Multi-cloud platforms allow deploying models across multiple cloud providers (e.g., AWS, Azure, GCP) for redundancy, flexibility, and cost optimization. Tools like Kubernetes, Docker, and cloud-agnostic APIs facilitate multi-cloud deployment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253d5c05",
   "metadata": {},
   "source": [
    "## Q9. Discuss the benefits and challenges of deploying machine learning models in a multi-cloud environment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594217c5",
   "metadata": {},
   "source": [
    "**Benefits:**\n",
    "- Redundancy and high availability\n",
    "- Avoid vendor lock-in\n",
    "- Optimize costs and performance\n",
    "\n",
    "**Challenges:**\n",
    "- Increased complexity in management and monitoring\n",
    "- Data consistency and security\n",
    "- Integration and compatibility issues"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
