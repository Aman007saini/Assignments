{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aaa57a4a",
   "metadata": {},
   "source": [
    "# Decision Tree 1: Concepts, Intuition, and Evaluation Metrics\n",
    "This notebook covers the decision tree classifier algorithm, mathematical and geometric intuition, binary classification, confusion matrix, and the importance of evaluation metrics (precision, recall, F1 score) with practical examples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f1946d",
   "metadata": {},
   "source": [
    "## Q1. Describe the decision tree classifier algorithm and how it works to make predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0680353",
   "metadata": {},
   "source": [
    "A decision tree classifier splits the data into branches based on feature values, creating a tree-like structure. At each node, it selects the feature and threshold that best separates the classes (using criteria like Gini impurity or entropy). Predictions are made by traversing the tree from the root to a leaf node based on the input features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76bb7452",
   "metadata": {},
   "source": [
    "## Q2. Provide a step-by-step explanation of the mathematical intuition behind decision tree classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60b95fc",
   "metadata": {},
   "source": [
    "1. For each feature, evaluate all possible splits.\n",
    "2. Calculate the impurity (e.g., Gini, entropy) for each split.\n",
    "3. Select the split that minimizes impurity in the resulting child nodes.\n",
    "4. Repeat recursively for each child node until a stopping criterion is met (e.g., max depth, min samples).\n",
    "5. Assign the most common class in each leaf node as the prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4434a10",
   "metadata": {},
   "source": [
    "## Q3. Explain how a decision tree classifier can be used to solve a binary classification problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e506617d",
   "metadata": {},
   "source": [
    "For binary classification, the tree splits the data into two classes at each node. At each leaf, the class with the majority of samples is assigned as the prediction. The process continues until all samples in a node belong to the same class or another stopping criterion is met."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55b90a4",
   "metadata": {},
   "source": [
    "## Q4. Discuss the geometric intuition behind decision tree classification and how it can be used to make predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6571da15",
   "metadata": {},
   "source": [
    "Geometrically, a decision tree partitions the feature space into axis-aligned rectangles (regions). Each split creates a boundary perpendicular to a feature axis. Predictions are made by determining which region (leaf) a new sample falls into."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc05a60",
   "metadata": {},
   "source": [
    "## Q5. Define the confusion matrix and describe how it can be used to evaluate the performance of a classification model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc3a1d8",
   "metadata": {},
   "source": [
    "A confusion matrix is a table showing the counts of true positives (TP), true negatives (TN), false positives (FP), and false negatives (FN). It helps evaluate model performance by showing how many predictions were correct or incorrect for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ebc5a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Confusion matrix for a decision tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "X, y = make_classification(n_samples=100, n_features=2, n_classes=2, random_state=42)\n",
    "tree = DecisionTreeClassifier()\n",
    "tree.fit(X, y)\n",
    "y_pred = tree.predict(X)\n",
    "cm = confusion_matrix(y, y_pred)\n",
    "print('Confusion matrix:\\n', cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5754d43b",
   "metadata": {},
   "source": [
    "## Q6. Provide an example of a confusion matrix and explain how precision, recall, and F1 score can be calculated from it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa614546",
   "metadata": {},
   "source": [
    "Example confusion matrix:\n",
    "\n",
    "|      | Predicted 0 | Predicted 1 |\n",
    "|------|-------------|-------------|\n",
    "| True 0 |     50      |      10     |\n",
    "| True 1 |     5       |      35     |\n",
    "\n",
    "- **Precision (class 1):** 35 / (35 + 10) = 0.78\n",
    "- **Recall (class 1):** 35 / (35 + 5) = 0.88\n",
    "- **F1 score:** 2 * (0.78 * 0.88) / (0.78 + 0.88) â‰ˆ 0.83"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b37fa6",
   "metadata": {},
   "source": [
    "## Q7. Discuss the importance of choosing an appropriate evaluation metric for a classification problem and explain how this can be done."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb524eb",
   "metadata": {},
   "source": [
    "Choosing the right metric depends on the problem context. For imbalanced data, accuracy may be misleading; use precision, recall, or F1 score. Consider the cost of false positives vs. false negatives and select metrics that align with business goals."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de06922c",
   "metadata": {},
   "source": [
    "## Q8. Provide an example of a classification problem where precision is the most important metric, and explain why."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d912a1",
   "metadata": {},
   "source": [
    "**Example:** Email spam detection. Precision is important because we want to minimize the number of legitimate emails incorrectly marked as spam (false positives)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba3d1cf",
   "metadata": {},
   "source": [
    "## Q9. Provide an example of a classification problem where recall is the most important metric, and explain why."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce06b22",
   "metadata": {},
   "source": [
    "**Example:** Disease screening. Recall is important because we want to identify as many actual cases as possible, even if it means some false positives (missing a disease case is more costly)."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
