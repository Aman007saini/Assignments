{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0787a1c1",
   "metadata": {},
   "source": [
    "# Statistics Advance 5 Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3643f954",
   "metadata": {},
   "source": [
    "## Q1. Calculate the 95% confidence interval for a sample of data with a mean of 50 and a standard deviation of 5 using Python. Interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a096f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Given values\n",
    "mean = 50\n",
    "std = 5\n",
    "n = 30  # assuming sample size is 30\n",
    "\n",
    "# 95% confidence interval\n",
    "confidence = 0.95\n",
    "z = stats.norm.ppf(1 - (1-confidence)/2)\n",
    "margin_of_error = z * (std / np.sqrt(n))\n",
    "ci_lower = mean - margin_of_error\n",
    "ci_upper = mean + margin_of_error\n",
    "\n",
    "print(f\"95% Confidence Interval: ({ci_lower:.2f}, {ci_upper:.2f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b5d7243",
   "metadata": {},
   "source": [
    "**Interpretation:**\n",
    "\n",
    "The 95% confidence interval gives a range in which we are 95% confident that the true population mean lies, based on our sample. If the interval is, for example, (48.21, 51.79), it means that if we were to take many samples and compute a confidence interval for each, about 95% of those intervals would contain the true mean."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d89736",
   "metadata": {},
   "source": [
    "## Q2. Explain the difference between a one-tailed and a two-tailed hypothesis test. Provide examples of when each would be appropriate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c63fa0",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "\n",
    "- **One-tailed test:** Tests for the possibility of the relationship in one direction. For example, testing if a new drug is *better* than the current drug (H₀: new ≤ current, H₁: new > current).\n",
    "- **Two-tailed test:** Tests for the possibility of the relationship in both directions. For example, testing if a new drug is *different* (either better or worse) than the current drug (H₀: new = current, H₁: new ≠ current).\n",
    "\n",
    "**When to use:**\n",
    "- Use a one-tailed test when you are only interested in deviations in one direction.\n",
    "- Use a two-tailed test when deviations in both directions are important."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5a8329",
   "metadata": {},
   "source": [
    "## Q4. What is a p-value? How is it used in hypothesis testing?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01df062a",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "\n",
    "A **p-value** is the probability of obtaining results at least as extreme as the observed results, assuming that the null hypothesis is true. In hypothesis testing, the p-value helps you decide whether to reject the null hypothesis:\n",
    "- If the p-value is less than the chosen significance level (e.g., 0.05), you reject the null hypothesis.\n",
    "- If the p-value is greater, you fail to reject the null hypothesis.\n",
    "\n",
    "The smaller the p-value, the stronger the evidence against the null hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c01985",
   "metadata": {},
   "source": [
    "## Q5. Calculate the p-value for a z-score of 2.0 in a right-tailed test using Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39bee388",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "z_score = 2.0\n",
    "# For a right-tailed test, p-value is the area to the right of z\n",
    "p_value = 1 - norm.cdf(z_score)\n",
    "print(f\"P-value for z=2.0 (right-tailed): {p_value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68054e75",
   "metadata": {},
   "source": [
    "**Interpretation:**\n",
    "\n",
    "A p-value of approximately 0.0228 means there is a 2.28% chance of observing a z-score of 2.0 or higher if the null hypothesis is true. If your significance level is 0.05, you would reject the null hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aafdc50f",
   "metadata": {},
   "source": [
    "## Q6. What is a Type I error and a Type II error? Provide examples of each."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e8045b",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "\n",
    "- **Type I Error (False Positive):** Rejecting the null hypothesis when it is actually true. Example: Concluding a new drug works when it actually does not.\n",
    "- **Type II Error (False Negative):** Failing to reject the null hypothesis when it is actually false. Example: Concluding a new drug does not work when it actually does."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95744d1",
   "metadata": {},
   "source": [
    "## Q7. What is statistical power? How can it be increased?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e480b3",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "\n",
    "- **Statistical power** is the probability that a test correctly rejects a false null hypothesis (i.e., detects an effect when there is one).\n",
    "- **How to increase power:**\n",
    "  - Increase sample size\n",
    "  - Increase effect size\n",
    "  - Increase significance level (alpha)\n",
    "  - Reduce variability in the data\n",
    "  - Use a more sensitive test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87142667",
   "metadata": {},
   "source": [
    "## Q8. What is the Central Limit Theorem (CLT)? Why is it important in statistics?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d39a31",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "\n",
    "The **Central Limit Theorem (CLT)** states that the sampling distribution of the sample mean approaches a normal distribution as the sample size increases, regardless of the population's distribution, provided the samples are independent and identically distributed.\n",
    "\n",
    "**Importance:**\n",
    "- Allows us to use normal probability theory to make inferences about population means, even when the population is not normally distributed.\n",
    "- Forms the basis for many statistical tests and confidence intervals."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346b8374",
   "metadata": {},
   "source": [
    "## Q11. What is the difference between parametric and non-parametric tests? Give examples of each."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e63cc7",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "\n",
    "- **Parametric tests** assume underlying statistical distributions in the data (e.g., normal distribution). They are generally more powerful if assumptions are met.\n",
    "  - Examples: t-test, ANOVA, Pearson correlation\n",
    "- **Non-parametric tests** do not assume a specific distribution. They are used when data do not meet parametric assumptions.\n",
    "  - Examples: Mann-Whitney U test, Wilcoxon signed-rank test, Kruskal-Wallis test, Spearman correlation"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
