{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67b13c0d",
   "metadata": {},
   "source": [
    "# Web Scraping Assignment\n",
    "\n",
    "## Q1. What is Web Scraping? Why is it Used? Give three areas where Web Scraping is used to get data.\n",
    "\n",
    "**Web Scraping** is the process of automatically extracting data from websites. It is used to collect large amounts of data from the web for analysis, research, or business purposes.\n",
    "\n",
    "**Why is it used?**\n",
    "- To gather data that is not readily available in a structured format.\n",
    "- To automate data collection from multiple sources.\n",
    "- To monitor changes or trends on websites.\n",
    "\n",
    "**Three areas where Web Scraping is used:**\n",
    "1. Price comparison websites (e.g., scraping product prices from e-commerce sites)\n",
    "2. Market research and sentiment analysis (e.g., scraping reviews or social media posts)\n",
    "3. Academic research (e.g., collecting data for scientific studies)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92d6edb",
   "metadata": {},
   "source": [
    "## Q2. What are the different methods used for Web Scraping?\n",
    "\n",
    "- Using built-in Python libraries like `urllib` and `http.client`\n",
    "- Using third-party libraries such as `requests` for HTTP requests\n",
    "- Parsing HTML/XML with libraries like `BeautifulSoup` or `lxml`\n",
    "- Using browser automation tools like `Selenium` or `Playwright` for dynamic content\n",
    "- APIs provided by websites (if available)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561534e1",
   "metadata": {},
   "source": [
    "## Q3. What is Beautiful Soup? Why is it used?\n",
    "\n",
    "**Beautiful Soup** is a Python library used for parsing HTML and XML documents. It creates a parse tree from page source code, making it easy to extract data from HTML tags.\n",
    "\n",
    "**Why is it used?**\n",
    "- To navigate, search, and modify the parse tree easily.\n",
    "- To extract specific data from web pages efficiently.\n",
    "- To handle poorly formatted or invalid HTML gracefully."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f098f7",
   "metadata": {},
   "source": [
    "## Q4. Why is flask used in this Web Scraping project?\n",
    "\n",
    "Flask is used to create a web interface for the web scraping project. It allows users to interact with the scraper through a browser, submit URLs or parameters, and view the scraped results in a user-friendly format."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173e12cf",
   "metadata": {},
   "source": [
    "## Q5. Write the names of AWS services used in this project. Also, explain the use of each service.\n",
    "\n",
    "**Common AWS services used in web scraping projects:**\n",
    "\n",
    "- **EC2 (Elastic Compute Cloud):** Used to host and run the web scraping scripts and Flask application on virtual servers.\n",
    "- **S3 (Simple Storage Service):** Used to store scraped data, logs, or output files.\n",
    "- **Lambda:** Used for serverless execution of scraping tasks or scheduled scraping jobs.\n",
    "- **CloudWatch:** Used for monitoring, logging, and alerting on the scraping process.\n",
    "\n",
    "**Explanation:**\n",
    "- EC2 provides scalable compute resources for running the application.\n",
    "- S3 offers durable and scalable storage for data.\n",
    "- Lambda allows running code without managing servers, ideal for lightweight or scheduled scraping tasks.\n",
    "- CloudWatch helps monitor application health and performance."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
