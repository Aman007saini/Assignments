{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0d8fdc1",
   "metadata": {},
   "source": [
    "# Introduction to Machine Learning - 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e43b6c1",
   "metadata": {},
   "source": [
    "## Q1: Define overfitting and underfitting in machine learning. What are the consequences of each, and how can they be mitigated?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda1d479",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "\n",
    "- **Overfitting:** The model learns the training data too well, including noise and outliers, resulting in poor generalization to new data. Consequences: High accuracy on training data, low accuracy on test data. Mitigation: Use more data, regularization, simpler models, cross-validation.\n",
    "- **Underfitting:** The model is too simple to capture the underlying pattern in the data. Consequences: Poor performance on both training and test data. Mitigation: Use more complex models, add features, reduce regularization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5bfee0f",
   "metadata": {},
   "source": [
    "## Q2: How can we reduce overfitting? Explain in brief."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b92831d",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "\n",
    "- Use more training data\n",
    "- Use regularization techniques (L1, L2)\n",
    "- Use simpler models\n",
    "- Use dropout (for neural networks)\n",
    "- Use cross-validation\n",
    "- Prune decision trees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26796c2a",
   "metadata": {},
   "source": [
    "## Q3: Explain underfitting. List scenarios where underfitting can occur in ML."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa8fb4c",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "\n",
    "Underfitting occurs when a model is too simple to capture the underlying structure of the data. Scenarios:\n",
    "- Using a linear model for non-linear data\n",
    "- Too few features\n",
    "- Too much regularization\n",
    "- Insufficient training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be65c0c4",
   "metadata": {},
   "source": [
    "## Q4: Explain the bias-variance tradeoff in machine learning. What is the relationship between bias and variance, and how do they affect model performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5491967d",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "\n",
    "- **Bias:** Error due to overly simplistic assumptions in the model.\n",
    "- **Variance:** Error due to model sensitivity to small fluctuations in the training set.\n",
    "\n",
    "High bias leads to underfitting, high variance leads to overfitting. The tradeoff is to find a balance for optimal model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f04721d",
   "metadata": {},
   "source": [
    "## Q5: Discuss some common methods for detecting overfitting and underfitting in machine learning models. How can you determine whether your model is overfitting or underfitting?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6c0e83",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "\n",
    "- Compare training and validation/test accuracy:\n",
    "  - High training, low test accuracy: Overfitting\n",
    "  - Low training and test accuracy: Underfitting\n",
    "- Use learning curves\n",
    "- Cross-validation\n",
    "- Residual analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2766772",
   "metadata": {},
   "source": [
    "## Q6: Compare and contrast bias and variance in machine learning. What are some examples of high bias and high variance models, and how do they differ in terms of their performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dddaf57",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "\n",
    "- **High bias models:** Linear regression on non-linear data, shallow decision trees. Poor on both training and test data.\n",
    "- **High variance models:** Deep decision trees, high-degree polynomial regression. Good on training, poor on test data.\n",
    "\n",
    "High bias = underfitting, high variance = overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ab64d1",
   "metadata": {},
   "source": [
    "## Q7: What is regularization in machine learning, and how can it be used to prevent overfitting? Describe some common regularization techniques and how they work."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd27f8f",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "\n",
    "Regularization adds a penalty to the loss function to discourage complex models and prevent overfitting.\n",
    "- **L1 regularization (Lasso):** Adds the sum of absolute values of coefficients.\n",
    "- **L2 regularization (Ridge):** Adds the sum of squared values of coefficients.\n",
    "- **Dropout:** Randomly drops neurons during training (for neural networks).\n",
    "\n",
    "These techniques help keep the model simpler and improve generalization."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
